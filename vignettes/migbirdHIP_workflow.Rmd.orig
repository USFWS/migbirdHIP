---
title: "The migbirdHIP Workflow"
package: migbirdHIP
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The migbirdHIP Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Table of Contents

-   [Introduction](#introduction)
    -   [Installation](#installation)
        -   [Releases](#releases)
    -   [Load](#load)
    -   [Functions overview](#functions-overview)
-   [Part A: Data Import and Cleaning](#part-a-data-import-and-cleaning)
    -   [fileRename](#filerename)
    -   [fileCheck](#filecheck)
    -   [read_hip](#read_hip)
    -   [glyphCheck](#glyphcheck)
    -   [shiftCheck](#shiftcheck)
    -   [clean](#clean)
    -   [issueCheck](#issuecheck)
    -   [duplicateFinder](#duplicatefinder)
    -   [duplicatePlot](#duplicateplot)
    -   [duplicateFix](#duplicatefix)
    -   [bagCheck](#bagcheck)
-   [Part B: Data Proofing and Correction](#part-b-data-proofing-and-correction)
    -   [proof](#proof)
    -   [correct](#correct)
    -   [pullErrors](#pullerrors)
    -   [write_hip](#write_hip)
    -   [writeReport](#writereport)
-   [Part C: Data Visualization and Tabulation](#part-c-data-visualization-and-tabulation)
    -   Visualization
        -   [errorPlotFields](#errorplotfields)
        -   [errorPlotStates](#errorplotstates)
        -   [errorPlotDL](#errorplotdl)
    -   Tabulation
        -   [errorTable](#errortable)
        -   [redFlags](#redflags)
-   [Troubleshooting](#troubleshooting)
    -   [Common read_hip warnings](#common-read_hip-warnings)
    -   [Memory problems](#memory-problems)
    -   [Other](#other)

## Introduction {#introduction}

The `migbirdHIP` package was created by the U.S. Fish and Wildlife Service (USFWS) to process, clean, and visualize Harvest Information Program (HIP) registration data.

Every year, migratory game bird hunters must register for HIP in the state(s) they plan to hunt by providing their name, address, date of birth, and hunting success from the previous year. All 49 contiguous states are responsible for collecting this information and submitting hunter registrations to the USFWS. Raw data submitted by the states are processed in this package.

The USFWS has been using HIP registrations since 1999 to select hunters for the Migratory Bird Harvest Survey (Diary Survey) and the Parts Collection Survey (Wing Survey). Only a small proportion of HIP registrants are chosen to complete these surveys each year. The USFWS ultimately uses these data to generate annual harvest estimates. To read more about HIP and the surveys, visit: <https://www.fws.gov/harvestsurvey/> and <https://www.fws.gov/library/collections/migratory-bird-hunting-activity-and-harvest-reports>

### Installation {#installation}

The package can be installed from the USFWS GitHub repository using:

```{r, install, eval = FALSE}
devtools::install_github("USFWS/migbirdHIP", quiet = T, upgrade = F, , build_vignettes = T)
```

#### Releases {#releases}

To install a past release, use the example below and substitute the appropriate version number.

```{r, releases, eval = FALSE}
devtools::install_github("USFWS/migbirdHIP@v1.2.8", build_vignettes = T)
```

### Load {#load}

Load `migbirdHIP` after installation. The package will return a startup message with the version you have installed and what season of HIP data the package version was intended for.

```{r setup}
library(migbirdHIP)
```

### Functions overview {#functions-overview}

The flowchart below is a visual guide to the order in which functions are used. Some functions are only used situationally and some issues with the data cannot be solved using a function at all. The general process of handling HIP data is demonstrated here; every function in the `migbirdHIP` package is included.

```{r flowchart_svg, echo = FALSE, fig.cap = "Overview of migbirdHIP functions in a flowchart format.", out.width = "100%", dev = "svg", fig.align = "center"}
knitr::include_graphics("image/migbirdHIP_flowchart.svg")
```

## Part A: Data Import and Cleaning {#part-a-data-import-and-cleaning}

### fileRename {#filerename}

The `fileRename` function renames non-standard file names to the standard format. We expect a file name to be a 2-letter capitalized state abbreviation followed by YYYYMMDD (indicating the date data were submitted).

Some states submit files using a 5-digit file name format, containing 2 letters for the state abbreviation followed by a 3-digit Julian date. To convert these 5-digit filenames to the standard format (a requirement to read data properly with [read_hip](#read_hip)), supply `fileRename` with the directory containing HIP data. File names will be automatically overwritten with the YYYYMMDD format date corresponding to the submitted Julian date.

This function also converts lowercase state abbreviations to uppercase.

The current hunting season year must be supplied as a parameter to accurately convert dates.

```{r rename, eval = FALSE}
fileRename(path = "C:/HIP/raw_data/DL0901", year = 2024)
```

### fileCheck {#filecheck}

Check if any files in the input folder have already been written to the processed folder.

```{r filecheck, eval = FALSE}
fileCheck(
  raw_path = "C:/HIP/raw_data/DL0901/",
  processed_path = "C:/HIP/corrected_data/"
)
```

### read_hip {#read_hip}

Read HIP data from fixed-width .txt files using `read_hip`. Files must adhere to a 10-character naming convention to successfully be read in (2-letter capitalized state abbreviation followed by YYYYMMDD). If files were submitted with a 5-digit format or lowercase state abbreviation, run [fileRename](#filerename) first.

The `read_hip` function allows data to be read in for:

-   all states (e.g. `state = NA`, the default)
-   a specific state (e.g. `state = "DE"`)
-   a specific download (e.g. `season = FALSE`, the default)
-   an entire season (e.g. `season = TRUE`)

Use `unique = TRUE` to read in a frame without exact duplicates, or `unique = FALSE` to read in all records including exact duplicates. This function also:

-   Returns a message if one or more files are blank in the directory
-   Return a message by download state for records with blank or NA values in firstname, lastname, state, or birth date
-   Checks download state abbreviations in the .txt file names
-   Trims whitespace on all values
-   Converts "N/A" strings to NA
-   Creates a dl_state, dl_date, dl_cycle, and source_file column from each .txt filename
-   Creates a dl_key column by grouping data by dl_state and dl_date
-   Creates a record_key column (unique identifier for each row, used later by other functions)

We will use the default settings to read in all of the states from download 0901. Fake HIP data files located in the `extdata/DL0901/` directory of the R package will be used as an example.

```{r, readhip}
raw_data <- read_hip(paste0(here::here(), "/inst/extdata/DL0901/"))
```

### glyphCheck {#glyphcheck}

During pre-processing, R may throw an error that says something like "invalid UTF-8 byte sequence detected". The error usually includes a field name but no other helpful information. The `glyphCheck` function identifies values containing non-UTF-8 glyphs/characters and prints them with the source file in the console so they can be edited.

```{r glyphCheck, eval = FALSE}
glyphCheck(raw_data)
```

### shiftCheck {#shiftcheck}

Find and print any rows that have a line shift error.

```{r shiftCheck, eval = FALSE}
shiftCheck(raw_data)
```

### clean {#clean}

Clean the data after it has been read and checked.

```{r, clean}
clean_data <- clean(raw_data)
```

The `clean` function does simple data cleaning. Importantly, records are discarded if first name, last name, birth date, state of residence, address AND email, OR city AND zip AND email are missing.

Other quick fixes include:

-   Converts names to uppercase
-   Moves suffixes from first or last name columns to the appropriate suffix column (including any value from I to XX or 1ST to 20TH, except for XVIII)
-   If any value other than a letter is in the middle initial column, it's set to NA
-   Zip code correction
    -   Removes ending hyphen from zip codes with only 5 digits
    -   Trims 0s from 10th digit
    -   Inserts a hyphen in continuous 9 digit zip code values
    -   Inserts a hyphen in 9 digit zip codes with a middle space
    -   Deletes trailing -0000 and -\_\_\_\_ from zip codes
-   Address cleaning
    -   Deletes leading "." in addresses (a spillover character from suffix)
    -   Attempt at PO Box standardization, by changing "P.O.BOX" to "PO BOX" and "P.O. BOX" to "PO BOX"
-   Trims whitespace on all values (again)

### issueCheck {#issuecheck}

The `issueCheck` function filters out past registrations, returns messages for records received that should be saved for the future, and plots records that have a disagreement between registration year and issue date. To skip plotting, specify `plot = F`.

```{r, issuecheck, eval = F}
current_data <- issueCheck(clean_data, year = 2024, plot = F)
```

```{r, createcurrent, include = F}
current_data <- clean_data
```

### duplicateFinder {#duplicatefinder}

The `duplicateFinder` function finds hunters that have more than one registration. Records are grouped by first name, last name, state, birth date, and download state to identify unique hunters. If the same hunter has 2 or more registrations, the fields that are not identical are counted and summarized.

```{r findDuplicates_tbl}
duplicateFinder(current_data)
```

### duplicatePlot {#duplicateplot}

Plot duplicates.

```{r, duplicatePlot, fig.cap = "Figure 1. Plot of types of duplicates.", fig.width = 6, fig.height = 3.5, dpi = 300, out.width = 500, fig.align = "center"}
duplicatePlot(current_data)
```

### duplicateFix {#duplicatefix}

We sometimes receive multiple HIP records per person which must be resolved by `duplicateFix`. Only 1 HIP record per hunter can be kept. To decide which record to keep from a group, we follow a series of logic.

Records are kept when they meet the below criteria (in order of importance):

1.  The record in the group has the most recent issue date.
2.  Records do not contain all 1s or all 0s in bag columns.
3.  For duplicates from sea duck and brant states (AK, CA, CT, DE, MA, MD, NC, NH, NJ, NY, RI, VA), keep records with a 2 in seaduck or brant.
4.  For duplicates from seaduck-only state (ME), keep records with a 2 in seaduck.
5.  If records are tied, one is chosen randomly.

A new field called "record_type" is added to the data after the above deduplicating process. Every HIP record is labeled "HIP". Permit states WA and OR send HIP and permit records separately, which are labeled "HIP" and "PMT" respectively.

Note: This function replaces "." values with NA in non-permit species columns for WA and OR records.

```{r, duplicateFix}
deduplicated_data <- duplicateFix(current_data)
```

### bagCheck {#bagcheck}

Running `bagCheck` ensures species "bag" values are in order. This function searches for values in species group columns that are not typical or expected by the FWS. If a value outside of the normal range is detected, an output tibble is created. Each row in the output contains the state, species, unusual stratum value, and a list of the normal values we would expect.

If a value for a species group is given in the HIP data that doesn't match anything in our records, the species reported in the output will have NA values in the "normal_strata" column. These species are not hunted in the reported states.

```{r, bagCheck}
bagCheck(deduplicated_data)
```

## Part B: Data Proofing and Correction {#part-b-data-proofing-and-correction}

### proof {#proof}

After data are cleaned and checked for any important issues that would require manual attention, we `proof`:

```{r, proof}
proofed_data <- proof(deduplicated_data, year = 2024)
```

Data that are considered irregular are flagged in a new column called "errors". No actual corrections take place in this step; all data remain identical except for the new "errors" column. For each field, values are compared to standard expected formats and if they do not conform, the field name is pasted as a string in the "errors" column. Each row can have from zero errors (NA) to all column names listed. Multiple flags are hyphen delimited.

The year of the Harvest Information Program must be supplied as a parameter. This aids in checking dates when licenses were issued, as one example.

The data fields are evaluated as follows:

-   Test records are flagged if:
    - `firstname` and `lastname` are `"TEST"`
    - `lastname` is `"INAUDIBLE"`
    - `firstname` is one of: `"INAUDIBLE", "BLANK", "USER", "TEST", "RESIDENT"`
-   `title` should be one of: `r REF_TITLES`
-   `firstname` is flagged as an error if:
    -   Contains anything other than letters, apostrophe(s), space(s), and/or hyphen(s)
    -   Contains less than 2 letters
    -   Contains `"AKA"`
-   `middle` should be exactly 1 letter or `NA`
-   `lastname` is flagged as an error if:
    -   Contains anything except letters, apostrophe(s), space(s), hyphen(s), and/or period(s)
    -   Contains less than 2 letters
-   `suffix` should be one of: `r REF_SUFFIXES`
-   `address` is flagged if it contains a \|, tab, or non-UTF8 character
-   `city` is flagged as an error if:
    -   Contains anything other than letters, space(s), hyphen(s), apostrophe(s), and/or period(s)
    -   Contains less than 3 letters
-   `state` is flagged if it is not contained in the following list of abbreviations for US and Canada states, provinces, and territories:
    -   `r REF_USA_CANADA`
-   `zip` is flagged if the hunter's address doesn't have a zip that should be in their reported state of residence (checked against a master list of USA postal codes)
-   `birth_date` is flagged if the birth year was \> `100` or \< `0` years ago
-   `hunt_mig_birds` is flagged if it is not equal to `1` or `2`
-   `registration_yr` flagged if it is not equal to the HIP data collection year
-   `email` is flagged if:
    -   The email address is obfuscative (e.g. `none@gmail.com`, `nottoday@gmail.com`, `brian@na.com`, etc.)
    -  The address is longer than 100 characters
    -  A common domain name (e.g., gmail, yahoo) has a common typo
    -  A common domain name doesn't have a matching top-level domain (e.g., `gmail.net` or `hotmail.gov`)
    -  The address has a bad top-level domain (e.g., `.comcom`, `.ccom`, etc.)
    -  The email is missing a top-level domain
    -  The top-level domain period is missing (e.g., `gmailcom`).

### correct {#correct}

After the download data are proofed, the next step is to fix the data to the best of our ability. Data can be corrected by running the `correct` function on the proofed tibble. The year of the Harvest Information Program must be supplied as a parameter. Since the "errors" column is re-created using `correct`, supplying the year is necessary for the same reasons it is required by `proof`.

```{r correct}
corrected_data <- correct(proofed_data, year = 2024)
```

The following changes are made by the `correct` function if the field is flagged in the `errors` column:

-   `title` is changed to `NA`
-   `middle` is changed to `NA`
-   `suffix` is changed to `NA`

All functions in [Part C](#part-c-data-visualization-and-tabulation) will run on the corrected tibble, `corrected_data`, just as they worked on the example tibble `proofed_data`. Errors can be compared between the proofed stage and corrected stage to get a better idea of which errors were serious (i.e. difficult to correct automatically) and determine how serious errors can be prevented in the future.

### pullErrors {#pullerrors}

The `pullErrors` function can be used to view all of the actual values that were flagged as errors in a particular field. In this example, we find that the "suffix" field contains several values that are not accepted.

```{r pullerrors}
pullErrors(proofed_data, field = "suffix")
```

Running `pullErrors` on a field that has no errors will return a message.

```{r pullerrors2}
pullErrors(proofed_data, field = "dove_bag")
```

### write_hip {#write_hip}

After the data have been processed with `correct`, the table is ready to be written for the database. Use `write_hip` to do final processing to the table, which includes adding in FWS strata and setting NAs to blank strings. If `split = FALSE`, the final table will be saved as a single .csv to your specified path. If `split = TRUE` (default), one .csv file per each input .txt source file will be written to the specified directory.

```{r, writecsv, eval = FALSE}

write_hip(corrected_data, path = "C:/HIP/processed_data/")

```

### writeReport {#writereport}

The `writeReport` function can be used to automatically generate an R markdown document with figures, tables, and summary statistics. This can be done at the end of a download cycle.

```{r, writerpt, eval = FALSE}

# Windows only
memory.limit(size = 55000)

writeReport(
  raw_path = "C:/HIP/DL0901/",
  temp_path = "C:/HIP/corrected_data",
  year = 2024,
  dl = "0901",
  dir = "C:/HIP/dl_reports",
  file = "DL0901_report")

```

## Part C: Data Visualization and Tabulation {#part-c-data-visualization-and-tabulation}

### errorPlotFields {#errorplotfields}

The `errorPlotFields` function can be run on all states...

```{r errorfieldsplotall, fig.cap = "Figure 2. Plot of all location's errors by field name.", fig.width = 6, fig.height = 3.6, dpi = 300, out.width = 500, fig.align = "center"}
errorPlotFields(proofed_data, loc = "all", year = 2024)
```

... or it can be limited to just one.

```{r errorfieldsplotsc, fig.cap = "Figure 3. Plot of Louisiana's errors by field name.", fig.width = 6, fig.height = 3.6, dpi = 300, out.width = 500, fig.align = "center"}
errorPlotFields(proofed_data, loc = "LA", year = 2024)
```

It is possible to add any `ggplot2` components to these plots. For season total data specifically, the plot can be facet_wrapped using either dl_cycle or dl_date. The example below demonstrates how this package's functions can interact with the tidyverse and shows an example of an `errorPlotFields` facet_wrap (using a subset of 4 download cycles)

```{r errorfieldsfacet, eval = FALSE}
errorPlotFields(
  hipdata2024 |>
    filter(str_detect(dl_cycle, "0800|0901|0902|1001")),
    year = 2024) +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1),
    legend.position = "bottom") +
  facet_wrap(~dl_cycle, ncol = 2)
```

### errorPlotStates {#errorplotstates}

The `errorPlotStates` function plots error proportions per state. You may optionally set a threshold value to only view states above a certain proportion of error. Bar labels are error counts.

```{r errorplotstates, fig.cap = "Figure 5. Plot of proportion of error by state.", fig.width = 6, fig.height = 4, dpi = 300, out.width = 500, fig.align = "center"}
errorPlotStates(proofed_data)
```

### errorPlotDL {#errorplotdl}

This function should not be used unless you want to visualize an entire season of data. The `errorPlot_dl` function plots proportion of error per download cycle across the year. Location may be specified to see a particular state over time.

```{r errorPlotDL, eval = FALSE}
errorPlot_dl(hipdata2024, loc = "MI")
```

```{r errorplotdl_example, echo = FALSE, fig.cap = "errorPlot_dl example output", out.width = "70%", fig.align = "center"}
knitr::include_graphics("image/errorPlot_dl.png")
```

### errorTable {#errortable}

The `errorTable` function is a flexible way to obtain error data as a tibble, which can be assessed as needed or exported to create records of download cycle errors. The basic function reports errors by both location and field.

```{r errortable1}
errorTable(proofed_data)
```

Errors can be reported by only location by turning off the `field` parameter.

```{r errortable2}
errorTable(proofed_data, field = "none")
```

Errors can be reported by only field by turning off the `loc` parameter.

```{r errortable3}
errorTable(proofed_data, loc = "none")
```

Location can be specified.

```{r errortable4}
errorTable(proofed_data, loc = "CA")
```

Field can be specified.

```{r errortable5}
errorTable(proofed_data, field = "suffix")
```

Total errors for a location can be pulled.

```{r errortable6}
errorTable(proofed_data, loc = "CA", field = "none")
```

Total errors for a field in a particular location can be pulled.

```{r errortable7}
errorTable(proofed_data, loc = "CA", field = "dove_bag")
```

## Troubleshooting {#troubleshooting}

If you encounter a problem while using this R package, please [report an issue](https://github.com/USFWS/migbirdHIP/issues) on the [migbirdHIP GitHub repository](https://github.com/USFWS/migbirdHIP).
