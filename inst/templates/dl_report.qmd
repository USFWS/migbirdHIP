---
title: "Harvest Information Program"
subtitle: "Download Cycle Report"
date: today
format:
  html:
    theme: cosmo
    toc: false
    number-sections: false
    embed-resources: true
    anchor-sections: false
    include-in-header:
      - text: |
          <style>
          .cell-output-stdout code {
            word-break: break-word !important;
            white-space: pre-wrap !important;
          }
          </style>
params:
  raw_path:
    value: x
  temp_path:
    value: x
  dl:
    value: x
  year:
    value: x
---

```{r libs}
#| include: false

`%within%` <- lubridate::`%within%`

library(migbirdHIP)
library(sf) # Required to render map, otherwise get errors from indirect call
```

```{r read_data}
#| include: false

message_log <- list()

catch_messages <-
  function(fun) { 
    withCallingHandlers(
      fun,
      message = 
        function(m) {
          message_log[length(message_log) + 1] <<- m[1]
        }
    )
  }

dl_data <- 
  catch_messages(migbirdHIP::read_hip(params$raw_path)) |> 
  dplyr::mutate(dl_cycle = params$dl)
```

```{r data_processing}
#| include: false

# Record check
record_check <- 
  dl_data |>
  # Filter out records if firstname, lastname, state, birth date, OR address AND
  # email, OR city, zip AND email are missing -- records discarded because these
  # are needed to identify individuals Discard additional records if they are
  # missing elements of an address AND email
  dplyr::filter(
    dplyr::if_any(
      c("firstname", "lastname", "state", "birth_date"), ~is.na(.x))|
      dplyr::if_all(c("address", "email"), ~is.na(.x))|
      dplyr::if_all(c("city", "zip", "email"), ~is.na(.x)))

# Standardize birth date format
fixed_dates_data <-
  dl_data |> 
  dplyr::mutate(
    birth_date2 =
      ifelse(
        stringr::str_detect(birth_date, "^[0-9]{1}\\/"),
        paste0("0", birth_date),
        birth_date),
    birth_date3 =
      ifelse(
        stringr::str_length(birth_date2) == 9,
        paste0(
          stringr::str_sub(birth_date2, 1, 3),
          "0",
          stringr::str_sub(birth_date2, 4, 9)),
        birth_date2)) |> 
  dplyr::select(-c("birth_date", "birth_date2")) |>
  dplyr::rename(birth_date = birth_date3) |>
  dplyr::relocate(birth_date, .before = "issue_date") 

cleaned_data <- catch_messages(migbirdHIP::clean(fixed_dates_data))

fixed_dates_data <- NULL

current_data <- catch_messages(migbirdHIP::issueCheck(cleaned_data, params$year))

fixed_data <- catch_messages(migbirdHIP::fixDuplicates(current_data))

proofed_data <- migbirdHIP::proof(fixed_data, year = params$year)

fixed_data <- NULL

# Read in the completed download data (for better/more accurate figures and tables)
final_data <-
  purrr::map_df(
    1:length(list.files(params$temp_path)),
    ~data.table::fread(
      paste0(params$temp_path, list.files(params$temp_path)[.x]),
      colClasses = rep("character", 38),
      na.strings = "") |> 
      dplyr::select(1:28) |> 
      dplyr::rename(
        zip = postal_code,
        ducks_bag = Q_ducks,
        geese_bag = Q_geese,
        dove_bag = Q_doves,
        woodcock_bag = Q_woodcock,
        coots_snipe = Q_coot_snipe,
        rails_gallinules = Q_rail_gallinule,
        cranes = Q_cranes,
        band_tailed_pigeon = Q_bt_pigeons,
        brant = Q_brant,
        seaducks = Q_seaducks,
        dl_cycle = dl)) |> 
  migbirdHIP::proof(year = params$year) |> 
  dplyr::mutate(
    # Add the download date as a column
    dl_date =
      stringr::str_extract(source_file, "(?<=[A-Z]{2})[0-9]{8}(?=\\.txt)"))
```

```{r issue_checking_prelim}
#| echo: false
#| message: false

# Issue date checking
issue_assignments <- migbirdHIP:::issueAssign(cleaned_data, params$year)

bit <-
  issue_assignments |>
  dplyr::select(dl_state, source_file, issue_date, registration_yr, issue_eval) |>
  dplyr::left_join(
    migbirdHIP:::licenses_ref |>
      dplyr::select(
        -c("hunting_season", "category")) |> 
      dplyr::rename(dl_state = state),
    by = "dl_state") |>  
  dplyr::mutate(
    issue_date = lubridate::mdy(issue_date),
    type = 
      dplyr::case_when(
        # Issue date is before the first day of the hunting season 
        issue_date < issue_start ~ 
          "issue date before the first day of issuance (past records filtered out)",
        # Issue date is after issue_end (and is not 2 season state)
        issue_date > issue_end & issue_eval != "two season state" ~ 
          "issue date after end of issue window (bad)",
        TRUE ~ NA_character_
      )
  ) |> 
  dplyr::filter(!is.na(type)) |> 
  dplyr::mutate(message = paste("Records with", type, sep = " ")) |>
  dplyr::count(dl_state, message) |> 
  dplyr::arrange(dplyr::desc(n)) 

split_bit <- split(bit, bit$message)
  
bit <- NULL

```

```{r overview_statistics}
#| echo: false
#| message: false

# Summarize number of records from Canada
canada_records <-
  final_data |> 
  dplyr::select(state) |> 
  dplyr::filter(state %in% migbirdHIP:::abbr_canada) |> 
  nrow()

# Missing emails
emails_missing <-
  final_data |> 
  dplyr::select(source_file, dl_state, email, errors) |> 
  dplyr::mutate(
    errors = ifelse(is.na(errors), "na", errors),
    Category = 
      dplyr::case_when(
        !is.na(email) & !stringr::str_detect(errors, "email") ~ "Good",
        !is.na(email) & stringr::str_detect(errors, "email") ~ "Incorrect",
        is.na(email) ~ "Missing",
        TRUE ~ NA_character_)) 

# >90% email missing/incorrect 
emails_missing_flagged <-
  emails_missing |> 
  dplyr::select(-c("email", "errors")) |> 
  dplyr::group_by(source_file) |> 
  dplyr::mutate(total = dplyr::n()) |> 
  dplyr::ungroup() |> 
  dplyr::filter(Category != "Good") |> 
  dplyr::group_by(source_file) |> 
  # Calculate proportion of file with missing or incorrect emails
  dplyr::mutate(
    count = dplyr::n(),
    proportion = count/total) |> 
  dplyr::ungroup() |> 
  dplyr::select(-c("Category", "dl_state", "total")) |> 
  dplyr::distinct() |> 
  dplyr::filter(proportion >= 0.9) 

# Missing PII
pii_summary <- 
  record_check |> 
  dplyr::group_by(source_file) |> 
  dplyr::summarize(n = dplyr::n()) |> 
  dplyr::ungroup() |> 
  dplyr::left_join(
    dl_data |> 
      dplyr::select(source_file) |> 
      dplyr::group_by(source_file) |> 
      dplyr::mutate(total_rows = dplyr::n()) |> 
      dplyr::ungroup(),
    by = "source_file") |> 
  dplyr::mutate(prop = round(n/total_rows, digits = 2)) |> 
  dplyr::select(-total_rows) |> 
  dplyr::distinct() |> 
  dplyr::arrange(dplyr::desc(prop)) 

# 100% missing PII
pii2 <- pii_summary |> dplyr::filter(prop >= 0.1 | n >= 100)

# Issue dates errors
bad_issue <-
  cleaned_data |> 
  dplyr::group_by(source_file) |> 
  dplyr::mutate(file_total = dplyr::n()) |> 
  dplyr::ungroup() |> 
  dplyr::select(source_file, dl_state, file_total, issue_date) |> 
  dplyr::filter(
    !stringr::str_detect(
      issue_date, 
      "(0[1-9]|1[0-2])\\/(0[1-9]|[12][0-9]|3[01])\\/(2022|2023|2024)")) |> 
  dplyr::group_by(source_file, dl_state, file_total, issue_date) |> 
  dplyr::count() |> 
  dplyr::ungroup() |> 
  dplyr::mutate(prop = paste0(round((n/file_total), 2)*100, "%"))

`%>%` <- tidyr::`%>%`

# Captured messages
important_statistics <- 
  dplyr::bind_rows(
    message_log |> 
    unlist() |> 
    tibble::as_tibble() |> 
    dplyr::filter(
      !stringr::str_detect(
        value, 
        "reg_yr_eval|Current registrations with|are blank|ID fields|provided state|write-out|past records|0 future|issue_date in the|Mississippi|100% of emails|00/00/0000|2s converted|0 records need to be postponed|single digit")
    ) |> 
    dplyr::mutate(
      value = 
        stringr::str_remove(value, "^(Warning: |Error: |\\* )") %>%
        stringr::str_remove(., "\\\n$") %>%
        stringr::str_remove(., " They .+ registration_yr.") %>%
        paste0("* ", .)
      )
  ) 
    
rm(`%>%`)

# Blank files
blanks <-
  tibble::tibble(
    list.files(
      params$raw_path, recursive = F, pattern = "*\\.txt$", 
      ignore.case = T, full.names = TRUE) |>
    tibble::as_tibble_col(column_name = "filepath") |>
    # Don't process permit files
    dplyr::filter(!stringr::str_detect(filepath, "permit")) |>
    # Identify blank files
    dplyr::mutate(
      check =
        ifelse(
          file.size(filepath) == 0,
          "blank",
          ""))
  ) |> 
    dplyr::filter(check == "blank") |> 
    dplyr::transmute(
      files = 
        stringr::str_extract(
          filepath, "[A-Z]{2}[0-9]{8}\\.(txt|TXT)"))

# HuntY check table
huntcheck <-
  final_data |> 
  dplyr::select(source_file, hunt_mig_birds) |> 
  dplyr::group_by(source_file) |> 
  dplyr::mutate(total = dplyr::n()) |> 
  dplyr::ungroup() |> 
  dplyr::group_by(source_file, total, hunt_mig_birds) |> 
  dplyr::count() |> 
  dplyr::ungroup() |> 
  dplyr::filter(hunt_mig_birds != 2) |> 
  dplyr::mutate(prop = round(n/total, 2)) |> 
  dplyr::arrange(dplyr::desc(prop))

# Strata check table
stratacheck_tbl <- migbirdHIP::strataCheck(final_data)

stratacheck_tbl_non0 <- 
  stratacheck_tbl |> 
  dplyr::filter(prop != "0%")

# All horizontal validation
all_h_valid <- migbirdHIP::validate(final_data, type = "horizontal", all = T) 

# All 0s
all_h_valid_0s <- all_h_valid |> dplyr::filter(h_value == "0")

# Horizontal repetition for 100% of file
all_h_valid_100 <- all_h_valid |> dplyr::filter(prop_repeat == 1)

# Vertical repetition
vrep_all <- migbirdHIP::validate(final_data, type = "vertical", all = T) 

# Vertical repetition filtered
vrep_100 <-
  vrep_all |> 
  dplyr::filter(v_repeated >= 100) |> 
  # Filter out expected vertical repetition for bag values that are wrong, 
  # e.g. received 1s for no-season instead of 0s, etc; this already shows 
  # up in the stratacheck section and clutters the data summary here
  dplyr::left_join(
    migbirdHIP:::hip_bags_ref |>
      dplyr::select(-FWSstratum) |>
      dplyr::group_by(state, spp) |>
      dplyr::filter(dplyr::n() == 1) |>
      dplyr::ungroup() |>
      dplyr::rename(
        dl_state = state,
        repeated_value = stateBagValue) |>
      dplyr::mutate(
        repeated_value = as.character(repeated_value)) |>
      # Join in state/species combinations that are supposed to be
      # all 0s because we receive those bag values in another format
      dplyr::bind_rows(
        migbirdHIP:::pmt_files |> 
          dplyr::rename(repeated_value = value)) |>
      dplyr::distinct() |>
      dplyr::select(-repeated_value) |> 
      dplyr::mutate(flag = "no season"),
    by = c("dl_state", "spp")
    ) |> 
  dplyr::filter(is.na(flag)) |> 
  dplyr::select(-flag)

# Identical bags
identicalbags <- migbirdHIP::identicalBags(final_data) 

idb_filtered <-
  identicalbags |> 
  dplyr::filter(n > 100 & stringr::str_detect(value, ","))

if(nrow(idb_filtered) > 0) {
  idb2 <-
    idb_filtered |> 
    dplyr::group_by(dl_state, spp1, spp2, value) |> 
    dplyr::reframe(
      files = length(unique(source_file)),
      n = sum(n)) |> 
    dplyr::mutate(
      files = 
        ifelse(files == 1, " 1 file", paste0(files, " files")))
} else {
  idb2 <- idb_filtered
}

idb_filtered <- NULL

# Vector of source files
file_list <- 
  list.files(
    params$raw_path, 
    recursive = F, 
    pattern = "*\\.txt$", 
    ignore.case = TRUE)

# Duplicates for summary message
# List of permit records
pmts <-
  cleaned_data |>
  # Classify solo permit records as PMT
  dplyr::mutate_at(
    dplyr::vars(dplyr::matches("bag|coots|rails|cranes|band|brant|seaducks")),
    ~as.numeric(.)) |>
  dplyr::mutate(
    other_sum =
      rowSums(dplyr::across(dplyr::matches("bag|coots|rails")), na.rm = T),
    special_sum =
      rowSums(dplyr::across(dplyr::matches("cranes|band|brant|seaducks")), na.rm = T),
    record_type =
      ifelse(
        other_sum == 0 & special_sum > 0 & dl_state %in% unique(migbirdHIP:::pmt_inline$dl_state),
        "PMT",
        NA)) |>
  dplyr::filter(record_type == "PMT") |>
  dplyr::pull(record_key)

duplicates <-
  cleaned_data |>
  # Filter out permits
  dplyr::filter(!record_key %in% pmts) |>
  dplyr::group_by(source_file, dl_state) |> 
  dplyr::mutate(filesize = dplyr::n()) |> 
  dplyr::ungroup() |> 
  # Group by registrant information; first name, last name, state,
  # birthday, registration year, dl_state
  dplyr::group_by(
    firstname,
    lastname,
    state,
    birth_date,
    registration_yr,
    dl_state) |>
  # Filter out non-duplicate records
  dplyr::filter(dplyr::n() > 1) |>
  dplyr::ungroup() |>
  dplyr::group_by(dl_state, source_file, filesize) |> 
  dplyr::count() |> 
  dplyr::ungroup() |> 
  dplyr::group_by(dl_state) |> 
  dplyr::reframe(
    n_dupes = sum(n),
    n_files_with_dupes = dplyr::n(),
    total_records = sum(filesize),
    total_prop_dupes = n_dupes/total_records
  ) |> 
  dplyr::ungroup() |> 
  dplyr::mutate(
    n_files_with_dupes = 
      ifelse(
        n_files_with_dupes == 1,
        "in 1 file",
        paste("among", n_files_with_dupes, "files", sep = " ")
      ),
    total_prop_dupes =
      ifelse(
        round(total_prop_dupes, 2) < 0.01,
        "< 1%",
        paste0(round(total_prop_dupes, 2)*100, "%")
      )
    ) |> 
  dplyr::arrange(dplyr::desc(n_dupes))

# Number of registrations that are duplicated
# duplicate_individuals <-
#   cleaned_data |>
#   # Filter out permits
#   dplyr::filter(!record_key %in% pmts) |>
#   dplyr::group_by(source_file, dl_state) |> 
#   dplyr::mutate(filesize = dplyr::n()) |> 
#   dplyr::ungroup() |> 
#   # Group by registrant information; first name, last name, state,
#   # birthday, registration year, dl_state
#   dplyr::group_by(
#     firstname,
#     lastname,
#     state,
#     birth_date,
#     registration_yr,
#     dl_state) |>
#   # Filter out non-duplicate records
#   dplyr::filter(dplyr::n() > 1) |>
#   dplyr::ungroup() |> 
#   dplyr::select(
#     firstname,
#     lastname,
#     state,
#     birth_date,
#     registration_yr,
#     dl_state) |>
#   dplyr::n_distinct()


```

::: panel-tabset
# Agenda

## Download `r params$dl`

```{r summary_bullets}
#| echo: false
#| output: asis

bullets <- 
  c(
    # Count of received lines of data, files, states
    paste0(
      "* This cycle, ", 
      suppressWarnings(
        format.default(
          sum(migbirdHIP:::sumLines(params$raw_path)$num_lines),
          big.mark = ",")
        ), 
      " lines of data were submitted in ", 
      format.default(length(file_list), big.mark = ","), 
      " files from ",
      length(
        unique(
          stringr::str_extract(file_list, "^[A-Z]{2}"))), 
      " states.")
    ,
    # Count of retained lines of data, files, states
    paste0(
      "* We retained ", 
      format.default(nrow(final_data), big.mark = ","), 
      " unique records in the final data from ", 
      format.default(length(unique(final_data$source_file)), big.mark = ","),
      " files and ", 
      length(unique(final_data$dl_state)), 
      " states.")
    ,
    # Captured message outputs from other functions
    purrr::map(
      1:nrow(important_statistics),
      ~dplyr::slice(important_statistics, .x) |> dplyr::pull())
    , 
    # Canada summary
    if(canada_records > 0){
      paste0(
        "* A total of ", 
        format.default(canada_records, big.mark = ","), 
        " records were received from Canada.")
      }
  )

writeLines(unlist(bullets))

canada_records <- NULL
important_statistics <- NULL

```

## Blank files

```{r agenda_details_1}
#| echo: false
#| output: asis

if(nrow(blanks) > 0) {
  if(nrow(blanks) == 1) {
    cat(
      paste0(
      "❌", 
      " One file is blank in the directory."))
  } else if(nrow(blanks) > 1) {
    cat(
      paste0(
      "❌", 
      " ", nrow(blanks), 
      " files are blank in the directory."))
  }
  cat("\n\n")
  writeLines(
    unlist(
      purrr::map(
        1:nrow(blanks),
        ~paste0("* ", blanks$files[.x]))
    )
  )
} else {
  cat(paste0("✔️", " No files are blank in the directory."))
}
cat("\n\n")
cat("## Missing data")
cat("\n\n")
cat("### PII")
cat("\n\n")

if(nrow(pii2 |> dplyr::filter(prop >= 0.1 | n >= 100)) > 0) {
  if(nrow(pii2) == 1) {
    cat(
      paste0(
      "❌", 
      " One file is missing PII in > 10% or 100+ records."))
  } else if(nrow(pii2) > 1) {
    cat(
      paste0(
      "❌", 
      " ", nrow(pii2), 
      " files are missing PII in > 10% or 100+ records."))
  }
  cat("\n\n")
  pii2 |> 
    dplyr::mutate(prop = paste0(prop*100, "%")) |> 
    dplyr::rename(
      File = source_file,
      `Number of records` = n,
      `Proportion of file` = prop) |> 
    kableExtra::kbl() |> 
    kableExtra::kable_styling(full_width = F) |> 
    kableExtra::row_spec(
      1:nrow(pii2), extra_css = "padding: 3px;")
} else {
  cat(paste0("✔️", " No files are missing PII in > 10% or 100+ records."))
}

cat("\n\n")
cat("### Emails")
cat("\n\n")
if(nrow(emails_missing_flagged) > 0) {
  if(nrow(emails_missing_flagged) == 1) {
    cat(
      paste0(
      "❌", 
      " One file is missing > 90% of emails."))
  } else if(nrow(emails_missing_flagged) > 1) {
    cat(
      paste0(
      "❌", 
      " ", nrow(emails_missing_flagged), 
      " files are missing > 90% of emails."))
  }
  cat("\n\n")
  emails_missing_flagged |> 
    dplyr::mutate(proportion = paste0(proportion*100, "%")) |> 
    dplyr::rename(
      File = source_file,
      `Number of records` = count,
      `Proportion of file` = proportion) |> 
    kableExtra::kbl() |> 
    kableExtra::kable_styling(full_width = F) |> 
    kableExtra::row_spec(
      1:nrow(emails_missing_flagged), extra_css = "padding: 3px;")
} else {
  cat(paste0("✔️", " No files are missing > 90% of emails."))
}

cat("\n\n")
cat("## HuntY")
cat("\n\n")
if(nrow(huntcheck) > 0) {
  if(nrow(huntcheck) == 1) {
    cat(
      paste0(
        "❌", 
        " ",
        huntcheck$source_file,
        " reported ",
        paste0(huntcheck$prop*100, "%"),
        " HuntY = ", 
        huntcheck$hunt_mig_birds, "."))
  } else if(length(unique(huntcheck$source_file)) > 1) {
    cat(
      paste0(
        "❌", 
        " ", length(unique(huntcheck$source_file)), 
        " files reported HuntY other than 2."))
  }
  cat("\n\n")
  huntcheck |> 
    dplyr::mutate(prop = paste0(prop*100, "%")) |> 
    dplyr::select(
      File = source_file,
      HuntY = hunt_mig_birds,
      `Number of records` = n,
      `Proportion of file` = prop) |> 
    kableExtra::kbl() |> 
    kableExtra::kable_styling(full_width = F) |> 
    kableExtra::row_spec(
      1:nrow(huntcheck), extra_css = "padding: 3px;")
} else {
  cat(paste0("✔️", " No values other than HuntY = 2 submitted."))
}
```

## Bag values

::: panel-tabset

### Table

```{r stratacheck_agenda_tbl}
#| echo: false
#| output: asis

if(!is.null(stratacheck_tbl_non0)) {
  cat(paste0("❌", " Incorrect bag values detected (> 0% of file)."))
  cat("\n\n")
  
  kableExtra::kbl(
    stratacheck_tbl_non0 |> 
      dplyr::mutate(
        nprop = as.numeric(stringr::str_extract(prop, "[0-9]{1,3}"))) |>
      dplyr::arrange(dplyr::desc(nprop)) |> 
      dplyr::select(-nprop) |> 
      dplyr::rename(
        `State` = dl_state,
        Species = spp,
        `Strata provided` = state_strata,
        `Strata expected` = normal_strata,
        Count = n,
        Proportion = prop)) |> 
    kableExtra::kable_styling(full_width = T) |> 
    kableExtra::row_spec(
      1:nrow(stratacheck_tbl_non0), extra_css = "padding: 3px;")
    
} else { 
  cat(paste0("✔️", " All bag values are correct."))
}
```

### Bullets

```{r stratacheck_agenda_bullets}
#| echo: false
#| output: asis

if(!is.null(stratacheck_tbl_non0)) {
  cat(paste0("❌", " Incorrect bag values detected (> 0% of file)."))
  cat("\n\n")
  if(nrow(stratacheck_tbl_non0) == 1) {
    cat(
      paste0(
        "* ", stratacheck_tbl_non0$dl_state, " reported ", 
        stratacheck_tbl_non0$state_strata, " for ", 
        stratacheck_tbl_non0$prop, " of ", 
        stratacheck_tbl_non0$spp, 
        " (expected ", stratacheck_tbl_non0$normal_strata, ").")
    )
  } else if(nrow(stratacheck_tbl_non0) > 1) {
    stratacheck_split <- 
      split(
        stratacheck_tbl_non0 |> 
          dplyr::mutate(
            value = 
              ifelse(
                prop == "100%", 
                prop, 
                paste0(prop, " (n = ", n, ")"))), 
        stratacheck_tbl_non0$dl_state)
    
    writeLines(
      unlist(
        purrr::map(
          1:length(stratacheck_split),
          function(x) {
            list(
              paste0("* ", names(stratacheck_split[x])),
              purrr::map(
                1:nrow(stratacheck_split[[x]]),
                function(y) {
                  paste0(
                    "    + ",  
                    stratacheck_split[[x]]$state_strata[y], " for ", 
                    stratacheck_split[[x]]$value[y], " of ", 
                    stratacheck_split[[x]]$spp[y], 
                    " (expected ", stratacheck_split[[x]]$normal_strata[y], ")")
                }
              )
            )
          }
        )
      )
    )
  }
} else { 
  cat(paste0("✔️", " All bag values are correct."))
}

stratacheck_tbl_non0 <- NULL
```

:::

## Repeated and identical bag values

```{r agenda_details_2}
#| echo: false
#| output: asis

cat("### Identical bag columns")
cat("\n\n")
if(nrow(idb2) > 0) {
  cat(
    paste0(
      "❌", 
      " Indentical columns detected that contain more than 1 bag value in file(s) with more than 100 rows."))
  cat("\n\n")
  if(nrow(idb2) == 1) { 
    cat(
      paste0(
        "* ", idb2$dl_state, " reported identical ", 
        idb2$spp1, " and ", idb2$spp2, 
        " (n = ", idb2$n, 
        ", value(s) = ", idb2$value, ").")
    )
  } else if (nrow(idb2) > 1) { 
      idb2_split <- split(idb2, idb2$dl_state)
          
      writeLines(
        unlist(
          purrr::map(
            1:length(idb2_split),
            function(x) {
              list(
                paste0("* ", names(idb2_split[x]), " (", 
                 unique(idb2_split[[x]]$files), ")"),
                purrr::map(
                  1:nrow(idb2_split[[x]]),
                  function(y) {
                    paste0(
                      "    + ", 
                      idb2_split[[x]]$spp1[y], " and ", 
                      idb2_split[[x]]$spp2[y], 
                      " (records = ", idb2_split[[x]]$n[y], 
                      ", value(s) = ", idb2_split[[x]]$value[y], ")")
                  }
                )
              )
            }
          )
        )
      )
  }
} else {
  cat(paste0("✔️", " No identical bag columns were found in files with more than 100 rows, with more than 1 bag value in common."))
}

cat("\n\n")
cat("### All zero bags")
cat("\n\n")
if(nrow(all_h_valid_0s) > 0) {
  cat(
    paste0(
      "❌", 
      " Repeated 0s detected across bag fields. These records have been removed from the final data."))
  cat("\n\n")
  writeLines( 
    unlist(
      purrr::map(
        1:nrow(all_h_valid_0s),
          ~paste0(
            "* ", all_h_valid_0s$source_file[.x], " with ", 
            all_h_valid_0s$h_rep[.x], " record(s)")
      )
    )
  )  
} else {
  cat(paste0("✔️", " No horizontally repeated 0s detected."))
}
  
cat("\n\n")
cat("### Horizontal repetition")
cat("\n\n")
if(nrow(all_h_valid_100) > 0) {
  if(nrow(all_h_valid_100) == 1) {
    all_h_valid_var <- " file."
  } else if (nrow(all_h_valid_100) > 1) {
    all_h_valid_var <- " files."
  }
  cat(
    paste0(
      "❌", 
      " Horizontal repetition was found in 100% of ", 
      nrow(all_h_valid_100 |> dplyr::filter(prop_repeat == 1)), 
      all_h_valid_var))
  cat("\n\n")
  writeLines( 
    unlist(
      purrr::map(
        1:nrow(all_h_valid_100),
          ~paste0(
            "* ", all_h_valid_100$source_file[.x], " reported a value of ", 
            all_h_valid_100$h_value[.x], " across all bag fields for ", 
            all_h_valid_100$h_rep[.x], " records.")
      )
    )
  )  
} else {
  cat(paste0("✔️", " No horizontal repetition was found to cover 100% of a file."))
}

cat("\n\n")
cat("### Vertical repetition")
cat("\n\n")
if(nrow(vrep_100) > 0) { 
  cat(
    paste0(
      "❌", 
      " Vertical repetition was detected in file(s) with more than 100 rows. See Strata tab."))
  # cat("\n\n")
  # if(nrow(vrep_100) == 1) {
  # cat(
  #   paste0(
  #     "* ", vrep_100$source_file,
  #     " repeated ", vrep_100$repeated_value, 
  #     " for ", 
  #     vrep_100$spp,
  #     "(n = ", unique(vrep_100$v_repeated), 
  #     " records).")
  #   )
  # } else if(nrow(vrep_100) > 1) {
  #   vrep_100_split <- 
  #     split(vrep_100, vrep_100$source_file) |>
  #     setNames(
  #       vrep_100 |> 
  #         dplyr::distinct(source_file, v_repeated) |> 
  #         dplyr::pull(v_repeated))
  #   
  #   vrep_100_split <- 
  #     vrep_100_split[
  #       as.character(sort(as.numeric(names(vrep_100_split)), decreasing = T))]
  #   
  #   writeLines(
  #     unlist(
  #       purrr::map(
  #         1:length(vrep_100_split),
  #         function(x) {
  #           list(
  #             paste(
  #               "*",
  #               unique(vrep_100_split[[x]]$source_file),
  #               "(n =", unique(vrep_100_split[[x]]$v_repeated), 
  #               "records)", sep = " "),
  #             purrr::map(
  #               1:nrow(vrep_100_split[[x]]),
  #               function(y) {
  #                 paste0(
  #                   "    + ", vrep_100_split[[x]]$repeated_value[y], 
  #                   " for ", 
  #                   vrep_100_split[[x]]$spp[y])
  #               }
  #             )
  #           )
  #         }
  #       )
  #     )
  #   )
  # }
} else { 
  cat(paste0("✔️", " No vertical repetition detected."))
}

cat("\n\n")
cat("## Issue dates")
cat("\n\n")
if(nrow(bad_issue) > 0) {
  cat(paste0("❌", " Incorrectly formatted issue dates detected."))
  cat("\n\n")
  if(nrow(bad_issue) == 1) {
    if(bad_issue$n == 1) {
      bad_issue_n <- c("1 record")
    } else if (bad_issue$n > 1) {
      bad_issue_n <- paste(bad_issue$n, "records", sep = " ")
    }
    cat(
      paste0(
        "* ", bad_issue$source_file, 
        " has ", bad_issue_n, 
        " with ",
        bad_issue$issue_date, ".")
    )
  } else if(nrow(bad_issue) > 1) {
    writeLines(
      unlist(
        purrr::map(
          1:nrow(bad_issue),
            ~paste0(
              "* ", bad_issue$source_file[.x], " has ", 
              bad_issue$issue_date[.x], 
              " for issue_date in ",
              bad_issue$n[.x], " records (", 
              bad_issue$prop[.x], " of file).")
        )
      )
    )
  }
} else { 
  cat(paste0("✔️", " All issue dates formatted correctly."))
}
cat("\n\n")
cat("## Registrations out of season")
cat("\n\n")
if(length(split_bit) > 0) {
  cat(
    paste0(
      "❌", 
      " Issue dates found that don't fit within a current season window."))
  cat("\n\n")
  writeLines(
  unlist(
    purrr::map(
      1:length(split_bit),
      function(x) {
        list(
          paste(
            "*", names(split_bit[x]), sep = " "),
          purrr::map(
            1:nrow(split_bit[[x]]),
            function(y) {
              paste0(
                "    + ", split_bit[[x]]$n[y], 
                " from ", 
                split_bit[[x]]$dl_state[y])
            }
          )
        )
      }
    )
  )
)
} else { 
  cat(paste0("✔️", " All issue dates fall in the current season windows."))
}

cat("\n\n")
cat("## Duplicates")
cat("\n\n")
if(nrow(duplicates) > 0) { 
  dupe_prop <- 
    if(sum(duplicates$n_dupes)/nrow(cleaned_data) < 0.01) {
      "< 1%"
    } else {
      paste0(round(sum(duplicates$n_dupes)/nrow(cleaned_data), 3)*100, "%")
    }
  cat(
    paste0(
      "❌",
      " Out of ", nrow(cleaned_data), " records, ", 
      sum(duplicates$n_dupes), " (", 
      dupe_prop, ") were duplicated.")
  )
  cat("\n\n")
  duplicates <- dplyr::filter(duplicates, n_dupes >= 100 | dupe_prop >= 3)
  writeLines(
    unlist(
      purrr::map(
        1:nrow(duplicates),
          ~paste0(
            "* ", duplicates$dl_state[.x], " has ", 
            duplicates$n_dupes[.x], 
            " duplicates ",
            duplicates$n_files_with_dupes[.x], " (", 
            duplicates$total_prop_dupes[.x], " of records).")
      )
    )
  )
} else { 
  cat(paste0("✔️", " No duplicate records received."))
}

cat("\n\n")

idb2_split <- NULL
stratacheck_split <- NULL
vrep_100 <- NULL
vrep_100_split <- NULL
blanks <- NULL
pii2 <- NULL
bad_issue <- NULL
duplicates <- NULL
idb2 <- NULL
cleaned_data <- NULL
```

## High error proportions

States with more than 1% error before correction

```{r agenda_higherror_states}
#| echo: false

rfstate <-
  suppressMessages(
    migbirdHIP::redFlags(
      proofed_data, 
      type = "state", 
      threshold = 0.01) 
  )

if(!is.null(rfstate)) {
  kableExtra::kbl(
    rfstate |>
    dplyr::mutate(proportion = paste0(round(proportion, 2)*100, "%")) |>
    dplyr::select(
      State = dl_state,
      `Error count` = count_errors,
      `Correct count` = count_correct,
      Proportion = proportion)
    ) |>
    kableExtra::kable_styling(full_width = F) |> 
    kableExtra::row_spec(
      1:nrow(rfstate), extra_css = "padding: 3px;")
} else {
  cat("✔️ No states exceeded the error threshold!")
}

rfstate <- NULL
```

Fields with more than 1% error before correction

```{r agenda_higherror_fields}
#| echo: false

rffield <-
  suppressMessages(
    migbirdHIP::redFlags(
      proofed_data, 
      type = "field", 
      threshold = 0.01)
    )

if(nrow(rffield) > 0) {
  kableExtra::kbl(
    rffield |> 
      dplyr::mutate(proportion = paste0(round(proportion, 2)*100, "%")) |>
      dplyr::select(
        Field = errors,
        `Error count` = count_errors,
        `Correct count` = count_correct,
        Proportion = proportion
      )
    ) |>
    kableExtra::kable_styling(full_width = F) |> 
    kableExtra::row_spec(
      1:nrow(rffield), extra_css = "padding: 3px;")
} else {
  cat("✔️ No data fields exceeded the error threshold!")
}

rffield <- NULL
```

# Files

## Map

Files were received from the following yellow states. Hexagons shaded blue, orange, and gray did not submit files for this download.

```{r statemap}
#| message: false
#| warning: false
#| echo: false
#| fig-align: center

files_received <- 
    # Get all of the received files up to and including this download
    list.files(
      stringr::str_remove(params$raw_path, "\\/D.+"), recursive = T) |> 
    tibble::as_tibble() |> 
    tidyr::separate(value, into = c("dl", "file"), sep = "/", extra = "drop") |> 
    tidyr::separate(file, into = c("state", "date"), sep = 2, extra = "drop") |> 
    dplyr::select(-date) |> 
    dplyr::distinct() |> 
    dplyr::mutate(dl = stringr::str_remove(dl, "DL")) |> 
    # Keep only the download data information
    dplyr::filter(stringr::str_detect(dl, "^[0-9]{4}$")) |> 
    dplyr::mutate(dl = as.numeric(dl)) |> 
    # Discard any downloads before 0800 and keep only actual states
    dplyr::filter(dl >= 800 & state %in% datasets::state.abb) |> 
    # Filter out downloads that occur after this one
    dplyr::filter(dl <= as.numeric(params$dl)) |> 
    dplyr::group_by(dl) |> 
    dplyr::mutate(ord = dplyr::cur_group_id()) |> 
    dplyr::ungroup() |> 
    dplyr::group_by(state) |> 
    dplyr::mutate(most_recent_dl = max(dl)) |>
    dplyr::ungroup() |> 
    dplyr::filter(dl == most_recent_dl) |> 
    dplyr::mutate(
      lag = 
        ifelse(
          (max(ord) - ord) < 4,
          as.character(max(ord) - ord),
          "4+")) |> 
    dplyr::select(state, lag) |> 
    # Add an ID for the hex map
    dplyr::left_join(
      tibble::tibble(
        state = datasets::state.abb,
        id = datasets::state.name),
      by = "state"
    ) |> 
    dplyr::arrange(id)

if(params$dl == "0800") {
  cat("Map not available for this report.")
} else {
  
  migbirdHIP:::hexmap |>
    dplyr::left_join(files_received, by = c("id", "state")) |> 
    ggplot2::ggplot() +
    ggplot2::geom_sf(
      ggplot2::aes(geometry = geometry, fill = lag),
      color = "white") +
    ggplot2::geom_sf_text(
      ggplot2::aes(label = state),
      nudge_y = 0, size = 3.5) +
    ggplot2::labs(fill = "Downloads since\nfile(s) last received") +
    ggplot2::theme_void() +
    ggplot2::scale_fill_manual(
      values =
        c("#ffffb2", "#56B4E9", "#0072B2", "#E69F00", "#999999")) +
    ggplot2::theme(legend.position = "bottom") +
    ggplot2::guides(
      fill =
        ggplot2::guide_legend(
          label.vjust = -8.5, label.position = "top", title.vjust = 0.2))
}
```

## Records per state

The table below summarizes the total of number of records per download state in the final data.

```{r records_per_state}
#| message: false
#| echo: false

DT::datatable(
  final_data |> 
    dplyr::select(dl_state) |> 
    dplyr::group_by(dl_state) |> 
    dplyr::count() |> 
    dplyr::ungroup() |>
    dplyr::arrange(dplyr::desc(n)) |> 
    dplyr::rename(
      State = dl_state,
      `Number of records` = n
    ),
    extensions = "Buttons",
    options = 
      list(
        dom = "Bfrtip",
        buttons = c("csv", "excel", "pdf"))
  )

```

## Records excluded

```{r exclusions_per_state}
#| echo: false

excluded <- 
  files_received |> 
  dplyr::left_join(
    final_data |> 
      dplyr::select(state = dl_state) |> 
      dplyr::group_by(state) |> 
      dplyr::count() |> 
      dplyr::ungroup(),
    by = "state") |> 
  dplyr::mutate(none = ifelse(is.na(n) & lag == 0, "No records", NA)) |> 
  dplyr::filter(none == "No records") |> 
  dplyr::select(state) |> 
  dplyr::pull()
  
if(length(excluded) > 0) {
  cat(
    paste0(
      "❌",
      " These states submitted files for this download, but no records were used: ",
    paste0(excluded, collapse = ", ")))
  
  } else {
    cat("✔️ All download states that submitted files are included in the final data!")
}

files_received <- NULL
excluded <- NULL
```

# Missing Data

## Records removed due to missing PII

```{r pii_check}
#| echo: false
#| fig.align: center

if(nrow(record_check) > 0){
  cat(
    paste0(
      "The following records are missing first name, last name, date of birth, address AND email, OR city AND zip AND email. They are not included in the final data."
    )
  )
  
  missing_plot <-
    record_check |>
    dplyr::select(
      firstname, lastname, birth_date, state, address, city, zip, email) |>
    # Add an ID per row
    dplyr::mutate(hunter_id = dplyr::row_number()) |>
    # Pivot the field names to long format
    tidyr::pivot_longer(firstname:email, names_to = "field") |>
    # Only keep hunters' fields with NA values
    dplyr::filter(is.na(value)) |>
    # Set NA to 1 for plotting
    dplyr::mutate(value = 1) |>
    # Make a heat map
    ggplot2::ggplot(
      ggplot2::aes(x = field, y = as.factor(hunter_id), fill = value)) +
    ggplot2::geom_tile() +
    ggplot2::labs(y = "Hunter ID", x = "Data Field") +
    ggplot2::theme_classic() +
    ggplot2::theme(
      legend.position = "none",
      axis.text.y = ggplot2::element_blank(),
      axis.ticks.y = ggplot2::element_blank())
  
  print(missing_plot)
  } else {
    cat("✔️ No records detected with missing PII.")
  }
```

```{r pii_by_file}
#| echo: false

if(nrow(pii_summary) > 0) {
  cat(
    paste0(
      "❌", " There are ", nrow(record_check), " total records with missing PII. Below is a summary of the number of records missing from each HIP file."
      )
  )
  DT::datatable(
    pii_summary |> 
      dplyr::mutate(
        prop = paste0(round(prop, 2)*100, "%")) |> 
      dplyr::rename(
        `Source file` = source_file,
        `Number of records` = n,
        `Proportion` = prop)
    )
} 

pii_summary <- NULL
dl_data <- NULL
```

## Missing emails

Emails missing or detected to be incorrect are shown below. Values are sourced from the final data.

```{r missing_emails}
#| echo: false
#| fig.align: center
#| warning: false

emails_missing |> 
  dplyr::filter(Category != "Good") |> 
  dplyr::select(-c("source_file", "email", "errors")) |> 
  dplyr::group_by(dl_state) |> 
  dplyr::mutate(
    total_rows = dplyr::n(),
    total_proportion = dplyr::n()/nrow(final_data)) |> 
  dplyr::ungroup() |> 
  dplyr::group_by(dl_state, Category) |> 
  dplyr::mutate(proportion = dplyr::n()/nrow(final_data)) |> 
  dplyr::ungroup() |> 
  dplyr::distinct() |> 
  dplyr::group_by(dl_state) |> 
  # Create a label once per state (so that they are not overlaid on plot)
  dplyr::mutate(label = ifelse(dplyr::row_number() == 1, total_rows, NA)) |> 
  dplyr::ungroup() |> 
  # Plot
  ggplot2::ggplot() +
  ggplot2::geom_bar(
    ggplot2::aes(
      y = proportion,
      x = reorder(dl_state, total_rows),
      fill = Category),
    stat = "identity") +
  ggplot2::geom_text(
    ggplot2::aes(
      y = total_proportion,
      x = reorder(dl_state, total_rows),
      label = label,
      angle = 90),
    vjust = 0.2, hjust = -0.2) +
  ggplot2::labs(
    x = "State",
    y = "Emails (proportion)",
    title = "Erroneous emails by state") +
  ggplot2::scale_y_continuous(
    expand = ggplot2::expansion(mult = c(-0, 0.3))) +
  ggplot2::theme_classic() +
  ggplot2::theme(
    axis.text.x = 
      ggplot2::element_text(angle = 45, vjust = 1, hjust = 1)) +
  ggplot2::scale_fill_manual(
    "Category", 
    labels = c("Incorrect", "Missing"), 
    values = c("#F8766D", "grey35"))

```

# Strata

## HuntY response check

Files that submitted records with any value for `hunt_mig_birds` other than `2` are included in the table below.

```{r hunty_check}
#| echo: false

if(nrow(huntcheck) > 0) {
  DT::datatable(
    huntcheck |>
      dplyr::mutate(prop = paste0(prop*100, "%")) |> 
      dplyr::select(
        File = source_file,
        HuntY = hunt_mig_birds,
        `Number of records` = n,
        Proportion = prop
      )
    )
} else {
  cat("✔️ All HuntY = 2.")
}

huntcheck <- NULL
```

## Strata check

Export the strata issues table as a CSV, Excel, or PDF document by clicking a button below.

```{r stratacheck}
#| echo: false

if(!is.null(stratacheck_tbl)) { 
  DT::datatable(
    stratacheck_tbl |> 
      dplyr::mutate(
        nprop = as.numeric(stringr::str_extract(prop, "[0-9]{1,3}"))) |>
      dplyr::arrange(dplyr::desc(nprop)) |> 
      dplyr::select(-nprop) |> 
      dplyr::rename(
        `State` = dl_state,
        Species = spp,
        `Strata provided` = state_strata,
        `Strata expected` = normal_strata,
        Count = n,
        Proportion = prop
      ),
    extensions = "Buttons",
    options = 
      list(
        dom = "Bfrtip",
        buttons = c("csv", "excel", "pdf"))
    )
} else {
  cat("✔️ No strata abnormalities detected.")
}

stratacheck_tbl <- NULL
```

## Identical values

The table below shows files that contained identical columns for any combination of species fields in the final data. Identical columns detected for species without a season in a state are ignored. The `Count` field indicates the number of records that the file contained, and the `Value` field contains the value(s) that is/are the same between `Species 1` and `Species 2`.

```{r identical_bags}
#| echo: false

if(!is.null(identicalbags)) {
  DT::datatable(
    identicalbags |>
      dplyr::select(-dl_state) |> 
      dplyr::rename(
        `Source file` = source_file,
        `Species 1` = spp1,
        `Species 2` = spp2,
        Count = n,
        Value = value)
  )
} else {
  cat("✔️ No identical columns detected!")
}

identicalbags <- NULL
```

## Repeated values

### Horizontally repeated values across all bag fields

The table below shows how many records have horizontal repetition across ALL bag columns.

```{r h_validate}
#| echo: false

if(!is.null(all_h_valid)) {
  DT::datatable(
    all_h_valid |> 
    dplyr::mutate(prop_repeat = round(prop_repeat, digits = 2)) |> 
    dplyr::rename(
      `Source file` = source_file,
      Value = h_value,
      `Records repeated` = h_rep,
      `Total records` = h_total,
      `Proportion repeated` = prop_repeat)
  )
} else {
  cat("✔️ No horizontal repetition detected!")
}

all_h_valid <- NULL
```

### Vertically repeated values

The table below contains files with values repeated for 100% of any bag column. States without a season for a species are not included (e.g. MT does not have a seaducks season, so we expect 100% 0s for seaducks). The `Species` field indicates the species with vertically repeated values, the `Repetitions` field is the number of records, and the `Repeated value` field indicates what value was repeated.

```{r v_validate}
#| echo: false

if(!is.null(vrep_all)) {
  DT::datatable(
    vrep_all |> 
      dplyr::select(-dl_state) |> 
      dplyr::rename(
        `Source file` = source_file,
        `Species` = spp,
        `Repetitions` = v_repeated,
        `Repeated value` = repeated_value)
    )
} else { 
  cat("✔️ No vertical repetition detected!")
}

vrep_all <- NULL
```

# Issuance

## Summary of registration year

```{r reg_yr_check}
#| echo: false

suppressMessages(
  reg_yr_summary <-
    proofed_data |> 
    dplyr::select(registration_yr, dl_state) |> 
    # Filter out records from this year since we know they are good
    dplyr::filter(registration_yr != as.character(params$year)) |> 
    dplyr::group_by(registration_yr, dl_state) |> 
    dplyr::summarize(n = dplyr::n()) |> 
    dplyr::ungroup() |> 
    dplyr::rename(
      `Registration year` = registration_yr,
      State = dl_state,
      `Number of records` = n
    )
)

if(nrow(reg_yr_summary) > 0){
  cat(paste0("❌ Not all registration years = ", as.character(params$year), "."))
  DT::datatable(reg_yr_summary)
}else{
  cat(paste0("✔️ All registration years = ", as.character(params$year), "."))
}

reg_yr_summary <- NULL
```

## Non-current records

Records below did not have an issue date that is current.

```{r bad_issue_dates_plot}
#| echo: false
#| fig.align: center

if(nrow(dplyr::filter(issue_assignments, decision != "nochange")) > 0){
  migbirdHIP:::issuePlot(issue_assignments, params$year)
}else{
  cat("✔️ No bad data to plot.")
}
```

```{r bad_issue_dates_tbl}
#| echo: false
#| message: false

if(nrow(dplyr::filter(issue_assignments, decision != "nochange") |> dplyr::filter(!(dl_state %in% migbirdHIP:::states_twoseason & decision == "copy"))) > 0){
  stamp_format <- lubridate::stamp("Apr 15, 1993")
  
  bad_issue_table <-
    issue_assignments |>
    dplyr::filter(decision != "nochange") |>
    dplyr::filter(!(dl_state %in% migbirdHIP:::states_twoseason & decision == "copy")) |> 
    dplyr::select(dl_state, source_file, issue_date, registration_yr) |>
    dplyr::left_join(
      migbirdHIP:::licenses_ref |>
        dplyr::select(
          -c("hunting_season", "category")) |> 
        dplyr::rename(dl_state = state),
      by = "dl_state") |>
    dplyr::group_by(
      dl_state, source_file, registration_yr, issue_start, issue_end) |> 
    dplyr::summarize(
      n = dplyr::n(),
      `Error window` =
        paste(
          min(stamp_format(lubridate::mdy(issue_date))),
          max(stamp_format(lubridate::mdy(issue_date))),
          sep = " to ")
    )|> 
    dplyr::ungroup() |> 
    dplyr::relocate(n, .after = "source_file") |> 
    dplyr::mutate(
      `Issue window` = 
        paste(stamp_format(issue_start), 
              stamp_format(issue_end), sep = " to ")) |> 
    dplyr::select(-c("issue_start", "issue_end")) |> 
    dplyr::relocate(`Error window`, .after = `Issue window`) |> 
    dplyr::relocate(n, .after = registration_yr)
  
  DT::datatable(
    bad_issue_table |> 
      dplyr::rename(
        State = dl_state,
        File = source_file,
        Year = registration_yr,
        `Count outside window` = n
      )
  )
}

bad_issue_table <- NULL
```

## Future records

Records below have an issue date and registration year indicating they should be sampled until next year.

```{r future_records}
#| echo: false

if(nrow(dplyr::filter(issue_assignments, decision %in% c("postpone", "copy"))) > 0){
  DT::datatable(
    suppressMessages(
      issue_assignments |> 
        dplyr::filter(decision %in% c("postpone", "copy")) |>
        dplyr::group_by(dl_state, registration_yr) |>
        dplyr::count() |>
        dplyr::ungroup() |>
        dplyr::arrange(dplyr::desc(n))
      )
    )
} else {
  cat("✔️ No future records detected.")
}

```

## Past records

Records below have an issue date and registration year indicating they qualify for a previous HIP season. These records are not eligible to be sampled and were removed from the final data.

```{r past_records}
#| echo: false

if(nrow(dplyr::filter(issue_assignments, decision == "past")) > 0){
  DT::datatable(
    suppressMessages(
      issue_assignments |> 
        dplyr::filter(decision == "past") |>
        dplyr::group_by(dl_state, registration_yr) |>
        dplyr::count() |>
        dplyr::ungroup() |>
        dplyr::arrange(dplyr::desc(n))
      )
    )
} else {
  cat("✔️ No past records.")
}

issue_assignments <- NULL
```

# Duplicates

## Duplicate records

::: panel-tabset
## Before fixDuplicates (all 49 states)

```{r before_fixduplicates}
#| fig.align: center
#| echo: false

migbirdHIP::findDuplicates(current_data)

current_data <- NULL
```

## After fixDuplicates (all 49 states)

```{r after_fixduplicates}
#| echo: false
#| fig.align: center

fixed_dupes <- migbirdHIP::findDuplicates(proofed_data, return = "table")

if(!is.null(fixed_dupes)) {
  migbirdHIP::findDuplicates(proofed_data)
  
  DT::datatable(fixed_dupes)
} 

fixed_dupes <- NULL
```
:::

# Errors

## By field

::: panel-tabset
### Before correction

```{r errors_perfield_before}
#| echo: false
#| fig.align: center

migbirdHIP::errorPlot_fields(proofed_data, year = params$year, youth = T)
```

### After correction

```{r errors_perfield_after}
#| echo: false
#| fig.align: center
#| warning: false

# Get the order of the fields so that they match the plot above
x_order <-
  proofed_data |>
  dplyr::select(errors) |>
  # Pull errors apart, delimited by hyphens
  tidyr::separate(errors, into = as.character(c(1:25)), sep = "-") |>
  # Transform errors into a single column
  tidyr::pivot_longer(1:25, names_to = "name") |>
  dplyr::select(errors = value) |>
  dplyr::filter(!is.na(errors)) |>
  dplyr::group_by(errors) |>
  # Count number of correct values
  dplyr::summarize(count_errors = sum(!is.na(errors))) |>
  dplyr::ungroup() |>
  # Calculate error proportion
  dplyr::mutate(
    total = nrow(proofed_data),
    proportion = count_errors / nrow(proofed_data)) |>
  dplyr::arrange(proportion) |> 
  dplyr::select(errors) |> 
  dplyr::mutate(order = dplyr::row_number())

table_1 <-
  final_data |>
  dplyr::mutate(
    birth_year = 
      stringr::str_extract(birth_date, "(?<=\\/)[0-9]{4}$"),
    special =
      ifelse(
        birth_year > params$year - 16,
        "Youth Hunter",
        NA)) |>
  dplyr::select(errors, special) |>
  # Pull errors apart, delimited by hyphens
  tidyr::separate(errors, into = as.character(c(1:25)), sep = "-") |>
  # Transform errors into a single column
  tidyr::pivot_longer(1:25, names_to = "name") |>
  dplyr::select(errors = value, special) |>
  dplyr::filter(!is.na(errors))

# Step 2: table of errors with proportions calculated -- the youth
# errors must be row bound in
table_2 <-
  table_1 |>
  dplyr::group_by(errors) |>
  # Count number of correct and incorrect values
  dplyr::summarize(count_errors = sum(!is.na(errors))) |>
  dplyr::ungroup() |>
  dplyr::filter(errors != "birth_date") |>
  dplyr::bind_rows(
    table_1 |>
      dplyr::group_by(errors, special) |>
      dplyr::summarize(count_errors = sum(!is.na(errors))) |>
      dplyr::ungroup() |>
      dplyr::filter(errors == "birth_date")) |>
  # Calculate error proportion
  dplyr::mutate(
    total = nrow(final_data),
    proportion = count_errors / nrow(final_data))

# Labels for bar plot (birth_date color stack doesn't cooperate with
# positioning 2 labels, so we only label that field once at the top of
# the bar)
barlabels <-
  table_2 |>
  dplyr::select(-c("special", "total")) |>
  dplyr::group_by(errors) |>
  dplyr::mutate(
    count_errors = sum(count_errors),
    proportion = sum(proportion)) |>
  dplyr::ungroup()

# Plot
x_order |>
  dplyr::left_join(table_2, by = "errors") |> 
  dplyr::mutate(
    proportion = ifelse(is.na(proportion), 0, proportion),
    total = ifelse(is.na(total), 0, total)) |>
  dplyr::group_by(errors) |> 
  dplyr::mutate(
    count_errors = sum(count_errors),
    cumulative_prop = sum(proportion)) |> 
  dplyr::ungroup() |> 
  ggplot2::ggplot() +
  ggplot2::geom_bar(
    ggplot2::aes(
      x = stats::reorder(errors, order), 
      y = proportion, 
      fill = special),
    stat = "identity") +
  ggplot2::geom_text(
    ggplot2::aes(x = errors,
                 y = cumulative_prop,
                 label = count_errors,
                 angle = 90),
    vjust = 0.2, hjust = -0.2) +
  ggplot2::labs(
    x = "Field",
    y = "Error proportion",
    title = "Error proportion per field",
    fill = "Specifics") +
  ggplot2::scale_y_continuous(
    expand = ggplot2::expansion(mult = c(-0, 0.25))) +
  ggplot2::theme_classic() +
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(angle = 45, vjust = 1, hjust = 1)) +
  ggplot2::scale_fill_discrete(labels = "Youth Hunter", breaks = "Youth Hunter")

x_order <- NULL
table_1 <- NULL
table_2 <- NULL
barlabels <- NULL

```

### Bad zip codes

```{r badzips}
#| echo: false

# Summarize number of bad zip codes
zipcheck <- 
  final_data |> 
  dplyr::select(dl_state, state, zip) |> 
  dplyr::filter(!state %in% migbirdHIP:::abbr_canada) |> 
  dplyr::left_join(
    migbirdHIP:::zip_code_ref |>
      dplyr::select(zip = zipcode, zipState = state),
    by = "zip") |>
  dplyr::filter(state != zipState) |> 
  dplyr::group_by(dl_state, state, zip, zipState) |> 
  dplyr::count() |> 
  dplyr::ungroup() |>
  dplyr::arrange(dplyr::desc(n)) |> 
  dplyr::rename(
    `Download state` = dl_state,
    `Address state` = state,
    `Zip code` = zip,
    `Actual state` = zipState
  ) 

if(nrow(zipcheck) > 0){
  cat("The following table shows records in the final data with zip codes that do not match the address state.")
  
  DT::datatable(zipcheck)
}else{
  cat("✔️ No bad zip codes detected.")
}

zipcheck <- NULL
  
```
:::

```{r errortable}
#| include: false

et <- 
  migbirdHIP::errorTable(proofed_data, loc = "none") |>
  dplyr::arrange(dplyr::desc(error_count))
```

## Causes of errors for top 3 fields

💡 Some of these errors and issues may have been corrected. The values displayed are the errors that were caught for the three most incorrect fields this download.

::: panel-tabset
### Errors in `r et$error[1]`

```{r errortable_field1}
#| echo: false

if(et$error[1] != "birth_date"){
  err1 <- 
    migbirdHIP::pullErrors(
      proofed_data, field = et$error[1], distinct = FALSE) |> 
    tibble::as_tibble() |> 
    dplyr::mutate(
      value = stringi::stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) |>
    dplyr::group_by(value) |> 
    dplyr::summarize(count = dplyr::n()) |> 
    dplyr::ungroup() |> 
    dplyr::arrange(dplyr::desc(count))
  }else{
  err1 <- 
    migbirdHIP::pullErrors(
      proofed_data, field = et$error[1], distinct = FALSE) |> 
    tibble::as_tibble() |> 
    dplyr::mutate(value = stringr::str_extract(value, ".{4}$")) |> 
    dplyr::group_by(value) |> 
    dplyr::summarize(count = dplyr::n()) |> 
    dplyr::ungroup() |> 
    dplyr::arrange(dplyr::desc(count))
}

DT::datatable(err1)
```

### Errors in `r et$error[2]`

```{r errortable_field2}
#| echo: false

if(et$error[2] != "birth_date"){
  err2 <- 
    migbirdHIP::pullErrors(
      proofed_data, field = et$error[2], distinct = FALSE) |> 
    tibble::as_tibble() |> 
    dplyr::mutate(
      value = 
        stringi::stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) |>
    dplyr::group_by(value) |> 
    dplyr::summarize(count = dplyr::n()) |> 
    dplyr::ungroup() |> 
    dplyr::arrange(dplyr::desc(count))
  }else{
  err2 <- 
    migbirdHIP::pullErrors(
      proofed_data, field = et$error[2], distinct = FALSE) |> 
    tibble::as_tibble() |> 
    dplyr::mutate(value = stringr::str_extract(value, ".{4}$")) |> 
    dplyr::group_by(value) |> 
    dplyr::summarize(count = dplyr::n()) |> 
    dplyr::ungroup() |> 
    dplyr::arrange(dplyr::desc(count))
}

DT::datatable(err2)
```

### Errors in `r et$error[3]`

```{r errortable_field3}
#| echo: false

if(et$error[3] != "birth_date"){
  err3 <- 
    migbirdHIP::pullErrors(
      proofed_data, field = et$error[3], distinct = FALSE) |> 
    tibble::as_tibble() |> 
    dplyr::mutate(
      value = 
        stringi::stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) |>
    dplyr::group_by(value) |> 
    dplyr::summarize(count = dplyr::n()) |> 
    dplyr::ungroup() |> 
    dplyr::arrange(dplyr::desc(count))
  }else{
  err3 <- 
    migbirdHIP::pullErrors(
      proofed_data, field = et$error[3], distinct = FALSE) |> 
    tibble::as_tibble() |>  
    dplyr::mutate(value = stringr::str_extract(value, ".{4}$")) |> 
    dplyr::group_by(value) |> 
    dplyr::summarize(count = dplyr::n()) |> 
    dplyr::ungroup() |> 
    dplyr::arrange(dplyr::desc(count))
}

DT::datatable(err3)
```
:::

## By state

::: panel-tabset
### Before correction

```{r errors_perstate_before}
#| echo: false
#| fig.align: center

migbirdHIP::errorPlot_states(proofed_data)
```

### After correction

```{r errors_perstate_after}
#| echo: false
#| fig.align: center

migbirdHIP::errorPlot_states(final_data)

```
:::

## Causes of errors by state

::: panel-tabset

### Before correction

```{r errors_perstate_tbl_p}
#| echo: false

DT::datatable(
  migbirdHIP::errorTable(proofed_data, loc = "all") |> 
    dplyr::rename(
      State = dl_state,
      Error = error,
      Count = error_count)
  )
```

### After correction

```{r errors_perstate_tbl_c}
#| echo: false

DT::datatable(
  migbirdHIP::errorTable(final_data, loc = "all") |> 
    dplyr::rename(
      State = dl_state,
      Error = error,
      Count = error_count)
  )

final_data <- NULL
proofed_data <- NULL
```

:::
:::
